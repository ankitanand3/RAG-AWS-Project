# ===========================================
# RAG Q&A System - Environment Configuration
# ===========================================

# OpenAI Configuration (Required)
OPENAI_API_KEY=sk-proj-your-key-here

# Qdrant Configuration (Local Docker)
QDRANT_URL=http://localhost:6333
# QDRANT_API_KEY is not required for local Docker instance (no authentication by default)

# Collection Settings (Use the collection you created in Qdrant)
COLLECTION_NAME=project1

# Document Processing Settings
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Model Configuration
# EMBEDDING_MODEL options:
#   - text-embedding-3-small (1536 dimensions)
#   - text-embedding-3-large (3072 dimensions) - Better quality, higher cost
# NOTE: Must match your Qdrant collection's vector dimension!
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gpt-4o-mini
LLM_TEMPERATURE=0

# Retrieval Settings
RETRIEVAL_K=4

# Logging
LOG_LEVEL=INFO

# API Settings
API_HOST=0.0.0.0
API_PORT=8000

# Langsmith
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://eu.api.smith.langchain.com
LANGSMITH_API_KEY=XXXXXXXXX
LANGSMITH_PROJECT=rag-qa-production